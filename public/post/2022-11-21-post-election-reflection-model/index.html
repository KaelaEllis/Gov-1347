<!DOCTYPE html>
<html lang="en-us">
    <head>
		
		
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<title>Post Election Reflection Model &middot; My New Hugo Site</title>

		
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/fonts.css">
		
		<link rel="icon" href="/favicon.ico"/>
		<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

		
		<link href="" rel="alternate" type="application/rss+xml" title="My New Hugo Site" />

		<script src="/js/darkmode.js"></script>
	</head>

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/">
					
						<h2 class="nav-title">My New Hugo Site</h2>
					
				</a>
				<ul>
    
    
</ul>
			</div>
		</nav>

        <div id="darkModeToggle" onclick="toggleDarkMode()">
  &#9680; 
</div>

        

<main>
	


        <div class="post">
		<div class="post-info">
    <span>Written by</span>
        R package build
        <br>
        <span>on&nbsp;</span><time datetime="2022-11-21 00:00:00 &#43;0000 UTC">November 21, 2022</time>
</div>

		<h1 class="post-title">Post Election Reflection Model</h1>
<div class="post-line"></div>

		

		


<p>Welcome to my 2022 Midterm blog series. I’m Kaela Ellis, a junior at Harvard College studying Government. This semester I am taking Gov 1347: Election Analytics taught by Professor Ryan Enos, which has led to the creation of this blog. The goal of this blog series is to predict the 2022 Midterm election. With this blog series I predicted that Democrats would win 45.58466% of the vote share. While some of the election results are still contested, as of 11/21/2022, the Democrats won 48.32% of the popular vote.</p>
<pre><code>## [1] 45.58466</code></pre>
<pre><code>##            Model      Fit      lwr      upr
## 1 Dem Prediction 45.67219 42.77461 48.56978
## 2 Rep Prediction 54.32781 51.43022 57.22539</code></pre>
<p><img src="http://example.org/post/2022-11-21-post-election-reflection-model/index_files/figure-html/unnamed-chunk-3-1.png" width="672" />
In my forecast model, I used four variables from only midterm years dating back to 1954: approval rating, consumer sentiment, generic ballot, and incumbency. My model was formatted around predicting the incumbent party’s vote share largely because of retrospective voting theory. Under this theory, voters use elections to hold incumbents accountable; so, if their welfare has decreased, they won’t reelect the incumbent. Therefore, I compared the consumer sentiment and presidential approval rating to the incumbent president’s vote share. Using my four indicators, I obtained an R2 of 0.714, and a Democratic party loss of 45.58466% of the vote share. This prediction was 2.74% points lower than the actual Democratic two-party vote share of 48.32%. The prediction does fall in my predicted range, as my upper bound is 48.57%. However, my prediction was still significantly off, and in the remainder of this post I will examine different reasons for this result.</p>
<p><img src="http://example.org/post/2022-11-21-post-election-reflection-model/index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre><code>## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA

## Warning in mean.default(President): argument is not numeric or logical:
## returning NA</code></pre>
<pre><code>## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA

## Warning in mean.default(Party): argument is not numeric or logical: returning NA</code></pre>
<p><img src="http://example.org/post/2022-11-21-post-election-reflection-model/index_files/figure-html/unnamed-chunk-6-1.png" width="672" />
In the above models, I plotted the accuracy of each of my indicators. Looking at consumer sentiment, 2022 is not a novelty year. With a consumer sentiment of 59.9, its vote share falls directly on the trend line. Again, with approval rating, 2022 is relatively close to the line. With incumbency, which is a measure of the number of incumbent members running, 2022 again falls on the trend line. This same relationship is seen with the generic ballot. Based off of my four indicators 2022 does not seem to be a novelty year. However, when I examine these four graphs more closely, I notice a historical trend: the more recent the year, the closer it is to the trend line, and the less recent the year, the higher the likelihood of it being an outlier. Using a color scale, I visually represented this: the more recent the year, the more orange the year’s color is, and the less recent the year, the more green the year’s color is. The outliers tend to be green on all of these maps. Therefore, I hypothesized that in my attempts to have more data points, I included old years that threw off the accuracy of my model.</p>
<pre><code>## [1] 45.80753</code></pre>
<pre><code>##     model_recent      Fit      lwr      upr
## 1 Dem Prediction 45.67219 42.77461 48.56978
## 2 Rep Prediction 54.32781 51.43022 57.22539</code></pre>
<p>So, I tested this hypothesis. I removed half of the year from my dataset – all of the years that were green, which was any year prior to 1986. I reran my prediction model, and my prediction changed to 45.8%. This also bumped my R2 up from 0.714 to 0.752. This is slightly more accurate, but did not make a large difference. I suspect that while the older years were outliers, they violated the trend on either end of the scale, and thus canceled each other out.</p>
<p>I think one of the huge issue I had throughout this course was adjusting my predictions to match popular forcasters. I assumed that the forecasters, such as the Economist and Five-Thirty-Eight, were right and based the accuracy of my prediction off of their predictions. This created biases in my model. I cannot test the effect of this bias, but it is something to keep in mind.</p>
<p>Another potential flaw in my model was that I used incumbency as my model base, rather than party, meaning I measured how my variables interacted with the incumbent party vote share, rather than how they interacted with the Democratic or Republican party. My model assumed that the Democratic and Republican vote shares reacted the same to fundamentals. However, this is not true. For example, in my blog 3 post, I found a positive relationship between the consumer sentiment and Republican party vote share. However, when I performed the same test for the Democratic party, I found a negative relationship between consumer sentiment and the Democratic party vote share. This may indicate that voters attach certain fundamentals to certain parties. My statistical tests on consumer sentiment suggest that voters use economic fundamentals to evaluate the Republican party, but not the evaluate the Democratic party. Therefore, I hypothesize that I should have incorporated a party variable into my model.</p>
<pre><code>## [1] 45.47081</code></pre>
<pre><code>##      model_party      Fit      lwr      upr
## 1 Dem Prediction 45.67219 42.77461 48.56978
## 2 Rep Prediction 54.32781 51.43022 57.22539</code></pre>
<p>I tested my hypothesis by creating a party indicator. The R2 of this variable of this variable when input into the overall prediction model was -0.419 – it was my only negative R2. It slightly improved the R2 of the overall model from 0.714 to 0.721. However, this R2 increase is likely simply a proxy of adding an additional variable, which leads to overfitting. Additionally, my prediction became less accurate at 45.47%. Therefore, the interaction between my four variables and party seems to have minimal effect, if any.</p>


		
	</div>

	<div class="pagination">
		<a href="/post/2022-11-07-final-prediction/" class="left arrow">&#8592;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			
			<span>
			&copy; <time datetime="2022-11-22 21:16:22.202634 -0500 EST m=&#43;0.244484210">2022</time> . Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
